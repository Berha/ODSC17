{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# FORTUNE-TELLING WITH PYTHON: AN INTRO TO TIME SERIES MODELING\n",
    "## Jonathan Balaban\n",
    "#### Connect with me on [LinkedIn](https://www.linkedin.com/in/jbalaban) and [Github](https://github.com/ultimatist)\n",
    "\n",
    "![](https://img.evbuc.com/https%3A%2F%2Fcdn.evbuc.com%2Fimages%2F27728797%2F150577564943%2F1%2Foriginal.jpg?h=230&w=460&rect=0%2C165%2C932%2C466&s=0b175e424f9e6fe378d96daf5714fc50)\n",
    "\n",
    "## Introduction\n",
    "We often refer to our input features in machine learning as \"dimensions\". On that note, there's a dimension that pervades almost everything we do and observe as humans. It's the fourth dimension we experience every waking moment: time. But time is quite unlike other data we capture, and often requires unique machine learning approaches. These models and approaches are fairly established in  R and a few other languages, but have more recently immigrated to Python.\n",
    "\n",
    "In regession and classification, we use features (collected during a cross-sectional study/survey/measurement) to predict an outcome. The model and parameters represent part of the underlying relationship between features and outcome. But what if we run out of funds to cross-section (it's possible), or need to predict future outcomes for which the features aren't measurable or don't yet exist?\n",
    "\n",
    "### Examples of time series data and modeling (constant time interval):\n",
    "- Hedge fund prediction of stock and index movements\n",
    "- Long and short-term weather forecasting\n",
    "- Business budgeting and trend analysis\n",
    "- Health vitals monitoring\n",
    "- Traffic flows and logistic optimization modeling\n",
    "- Can you think of others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Time series data usually contains more than meets the eye, and can often be decomposed into trend, seasonal, and random fluctuation components.\n",
    "\n",
    "![Decomposition](http://rstatistics.net/wp-content/uploads/2014/09/Multiplicative-Decomposition-of-Time-series.png)\n",
    "\n",
    "- Trends\n",
    "    - Up\n",
    "    - Down\n",
    "    - Flat\n",
    "    - Larger trends can be made up of smaller trends\n",
    "    - There is no defined timeframe for what constitutes a trend; it depends on your goals\n",
    "- Seasonal Effects\n",
    "    - Weekend retail sales spikes\n",
    "    - Holiday shopping\n",
    "    - Energy requirement changes with annual weather patterns\n",
    "    - Note: twitter spikes when news happens are not seasonal; they aren't regular and predictable\n",
    "- Random Fluctuations\n",
    "    - The human element\n",
    "    - Aggregations of small influencers\n",
    "    - Observation errors\n",
    "    - The smaller this is in relation to Trend and Seasonal, the better we can predict the future\n",
    "    \n",
    "Time series models fall into [two camps](http://www.abs.gov.au/websitedbs/D3310114.nsf/home/Time+Series+Analysis:+The+Basics#HOW%20DO%20I%20KNOW%20WHICH%20DECOMPOSITION):\n",
    "- Additive\n",
    "    - Data = Trend + Seasonal + Random\n",
    "    - What we will be using for our modeling\n",
    "- Multiplicative\n",
    "    - Data = Trend x Seasonal x Random\n",
    "    - As easy to fit as Additive if we take the log\n",
    "        - log(Data) = log(Trend x Seasonal x Random)\n",
    "\n",
    "We should use multiplicative models when the percentage change of our data is more important than the absolute value change (e.g. stocks, commodities); as the trend rises and our values grow, we see amplitude growth in seasonal and random fluctuations. If our seasonality and fluctuations are stable, we likely have an additive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Time Series Modeling Process\n",
    "Time series model selection is driven by the Trend and Seasonal components of our raw data. The general approach for analysis looks like this:\n",
    "\n",
    "1. Plot the data and determine Trends and Seasonality\n",
    "    1. Difference or take the log of the data (multiple times if needed) to remove trends for [certain model applications](https://en.wikipedia.org/wiki/Stationary_process)\n",
    "    1. Stationairity is needed for ARMA models\n",
    "1. Determine if we have additive or multiplicative data patterns\n",
    "1. Select the appropriate algorithm based on the chart below\n",
    "1. Determine if model selection is correct with these tools\n",
    "    - Ljung-Box Test\n",
    "    - Residual Errors (Normal Distribution with zero mean and constant variance-homoskedastic, i.i.d)\n",
    "    - Autocorrelation Function (ACF)\n",
    "    - Partial Autocorrelation Function (PACF)\n",
    "\n",
    "Algorithm | Trend | Seasonal | Correlations\n",
    "---|---|---|---\n",
    "ARIMA | X |X|X\n",
    "SMA Smoothing |X||\n",
    "Simple Exponential Smoothing |X||\n",
    "Seasonal Adjustment |X|X|\n",
    "Holt's Exponential Smoothing |X||\n",
    "Holt-Winters |X|X|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## How to achieve and test for stationarity:\n",
    "\n",
    "- The mean of the series is not a function of time:\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Mean_nonstationary.png)\n",
    "\n",
    "- The variance of the series is not a function of time (homoscedasticity):\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Var_nonstationary.png)\n",
    "\n",
    "- The covariance at different lags is not a function of time:\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/02/Cov_nonstationary.png)\n",
    "\n",
    "[From A Complete Tutorial on Time Series Modeling in R](https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/)\n",
    "\n",
    "- [Info on stationarity](http://www.investopedia.com/articles/trading/07/stationary.asp)\n",
    "- Plotting Rolling Statistics\n",
    "    - Plot the moving average/variance and see if it changes with time. This visual technique can be done on different windows, but isn't as rigorously defensible as the test below.\n",
    "- Dickey-Fuller Test\n",
    "    - Statistical tests for checking stationarity; the null hypothesis is that the TS is non-stationary. If our test statistic is below an `alpha` value, we _can_ reject the null hypothesis and say that the series is stationary.\n",
    "\n",
    "$$ Y_t = \\rho * Y_{t-1} + \\epsilon_t \\\\$$\n",
    "$$  Y_t - Y_{t-1} = (\\rho - 1) Y_{t - 1} + \\epsilon_t \\\\$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install pyflux\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyflux as pf\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a play dataframe from 1-10 (linear and squared) to test how differencing works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# stationarize linear series (mean and variance doesn't change for sub-windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# stationarize squared series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# stationarize squared with log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Prep and EDA\n",
    "\n",
    "We'll be looking at [monthly average temperatures between 1907-1972](https://datamarket.com/data/set/22o4/mean-monthly-temperature-1907-1972#!ds=22o4&display=line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load data, recast columns if needed, convert to datetime\n",
    "monthly_temp = pd.read_csv('./mean-monthly-temperature-1907-19.csv', skipfooter=???, \n",
    "                           infer_datetime_format=True, header=???, index_col=0, names=['month', 'temp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# describe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# resample to annual and plot each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot both on same figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot with plotly (optional): might need a plotly account and key\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot binned yearly segments using resample method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# violinplot months to determine variance and range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Are these datasets stationary? We can look at a few things per the list above, including a visual check (there seems to be a small upward trend in the annual, too hard to tell for monthly), a standard deviation check on various differences (smallest one is usually most stationary), and the formal Dickey-Fuller test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check montly deviations for various diffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# check annual deviations for various diffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define Dickey-Fuller Test (DFT) function\n",
    "import statsmodels.tsa.stattools as ts\n",
    "def dftest(timeseries):\n",
    "    dftest = ts.adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','Lags Used','Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=12)\n",
    "    rolstd = pd.rolling_std(timeseries, window=12)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean and Standard Deviation')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run DFT on monthly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# run DFT on annual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ARIMA with Statsmodels\n",
    "Enter [Autoregressive Integrated Moving Average (ARIMA)](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) modeling. When we have autocorrelation between outcomes and their ancestors, we will see a theme, or relationship in the outcome plot. This relationship can be modeled in its own way, allowing us to predict the future with a confidence level commensurate to the strength of the relationship and the proximity to known values (prediction weakens the further out we go).\n",
    "\n",
    "- [ARIMA in R](https://www.otexts.org/fpp/8/5)\n",
    "- [Duke ARIMA Guide](https://people.duke.edu/~rnau/411arim2.htm)\n",
    "- [Great explanation on MA in practice](http://stats.stackexchange.com/questions/164824/moving-average-ma-process-numerical-intuition)\n",
    "\n",
    "### Autoregressive Models\n",
    "\n",
    "![AR Model](./ar.svg)\n",
    "\n",
    "Autocorrelation: a variable's correlation with itself at different lags.\n",
    "\n",
    "For second-order stationary (both mean and variance: $\\mu_t = \\mu$ and $\\sigma_t^2 = \\sigma^2$ for all $t$) data, autocovariance is expressed as a function only of the time lag $k$:\n",
    "\n",
    "$$ \\gamma_k = E[(x_t-\\mu)(x_{t+k} - \\mu)] $$\n",
    "  \n",
    "Therefore, the autocorrelation function is defined as:\n",
    "\n",
    "$$ \\rho_k = \\frac{\\gamma_k}{\\sigma^2} $$\n",
    "  \n",
    "We use the plot of these values at different lags to determine optimal ARIMA parameters. \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/ArTimeSeries.svg/685px-ArTimeSeries.svg.png)\n",
    "By Tomaschwutz - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=14740378\n",
    "\n",
    "\n",
    "Some things to note:\n",
    "1. AR models propagate shocks infinitely\n",
    "1. Current random error is the `epsilon` error term\n",
    "1. if a process depends on previous values of itself then it is an AR process. If it depends on previous errors than it is an MA process.\n",
    "1. AR processes will exhibit exponential decay in ACR and a cut-off in PACR\n",
    "\n",
    "### Moving Average Models (This is NOT a Simple/Weighted/Exponential Moving Average)\n",
    "\n",
    "![MA Model](./ma.svg)\n",
    "\n",
    "Some things to note:\n",
    "1. MA models do not propagate shocks infinitely; they die after `q` lags\n",
    "1. All previous errors up to a lag are rolled into the `epsilon` error term for that period\n",
    "1. if a process depends on previous values of itself then it is an AR process. If it depends on previous errors than it is an MA process.\n",
    "1. MA processes will exhibit exponential decay in PACR and a cut-off in ACR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![SARIMA Form](https://www.otexts.org/sites/default/files/fpp/images/sarima1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define helper plot function for visualization\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "def plots(data, lags=None):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper plot for monthly temps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### [Box-Jenkins Method](https://en.wikipedia.org/wiki/Box–Jenkins_method)\n",
    "\n",
    "ACF Shape|Indicated Model\n",
    "---|---\n",
    "Exponential, decaying to zero|Autoregressive model. Use the partial autocorrelation plot to identify the order of the autoregressive model.\n",
    "Alternating positive and negative, decaying to zero|Autoregressive model. Use the partial autocorrelation plot to help identify the order.\n",
    "One or more spikes, rest are essentially zero|Moving average model, order identified by where plot becomes zero.\n",
    "Decay, starting after a few lags|Mixed autoregressive and moving average (ARMA) model.\n",
    "All zero or close to zero|Data are essentially random.\n",
    "High values at fixed intervals|Include seasonal autoregressive term.\n",
    "No decay to zero|Series is not stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# we might need to install dev version for statespace functionality\n",
    "#!pip install git+https://github.com/statsmodels/statsmodels.git\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# fit SARIMA monthly based on helper plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot resids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot residual diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Statistical Tests\n",
    "\n",
    "\n",
    "- [Normality (Jarque-Bera)](http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_normality.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_normality)\n",
    "    - Null hypothesis is normally distributed residuals (good, plays well with RMSE and similar error metrics)\n",
    "\n",
    "- [Serial correlation (Ljung-Box)](http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_serial_correlation.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_serial_correlation)\n",
    "    - Null hypothesis is no serial correlation in residuals (independent of each other)\n",
    "\n",
    "- [Heteroskedasticity](http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_heteroskedasticity.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_heteroskedasticity)\n",
    "    - Tests for change in variance between residuals.\n",
    "    - The null hypothesis is of no heteroskedasticity. That means different things depending on which alternative is selected:\n",
    "        - Increasing: Null hypothesis is that the variance is not increasing throughout the sample; that the sum-of-squares in the later subsample is not greater than the sum-of-squares in the earlier subsample.\n",
    "        - Decreasing: Null hypothesis is that the variance is not decreasing throughout the sample; that the sum-of-squares in the earlier subsample is not greater than the sum-of-squares in the later subsample.\n",
    "        - Two-sided (default): Null hypothesis is that the variance is not changing throughout the sample. Both that the sum-of-squares in the earlier subsample is not greater than the sum-of-squares in the later subsample and that the sum-of-squares in the later subsample is not greater than the sum-of-squares in the earlier subsample.\n",
    "\n",
    "- [Durbin Watson](https://en.wikipedia.org/wiki/Durbin–Watson_statistic)\n",
    "    - Tests autocorrelation of residuals: we want between 1-3, 2 is ideal (no serial correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create and run statistical tests on model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Note on autofit methods\n",
    "R has an autoARIMA function (and other automagic methods) that gridsearches/optimizes our model parameters for us. Over time, more of these goodies are porting to Python (e.g. statsmodels.tsa.x13 import x13_arima_select_order). While there's nothing wrong with utilizing these resources, the _human makes the final determination!_ Don't become over-reliant on these methods, especially early on when you are grasping the underlying mechanics and theory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# autoselect for monthly, limited to only searching AR and MA parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# using itertools to gridsearch solutions\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# find optimal ARIMA for annual\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            model = sm.tsa.statespace.SARIMAX(annual_temp, order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False).fit()\n",
    "\n",
    "            print('ARIMA{},{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ARIMA with Pyflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# helper plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build and summarize model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot z-scores of feature coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot model against raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# predict future values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predicting Sunspots with Pyflux and ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read and plot data\n",
    "data = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/datasets/sunspot.year.csv') #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fit and summarize model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot z-scores of feature coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot in sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compare tail to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CO2 Levels and Forecasting\n",
    "Statsmodels has some 'built-in' time series datasets to play with, including one that tracks atmospheric CO2 from continuous air samples at Mauna Loa Observatory in Hawaii. This data includes CO2 samples from MAR 1958 to DEC 2001.\n",
    "\n",
    "[Credits](https://www.digitalocean.com/community/users/tvincent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# resample to monthly and check missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# decompose data into trend, seasonal, and residual\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# optimize our SARIMAX model using itertools: CAREFUL, this can take a while\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            model = sm.tsa.statespace.SARIMAX(co2, order=param,\n",
    "                        seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False).fit()\n",
    "\n",
    "            print('ARIMA{},{} - AIC:{}'.format(param, param_seasonal, model.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# create predictions and confidence intervals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compute mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# predict future dynamically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compute mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# forecast next 100 months and get confidence interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# plot forecast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Closing\n",
    "\n",
    "- Which areas of time series modeling are most interesting?\n",
    "- Which concepts are most challenging?\n",
    "- How will you apply these concepts to your work or personal projects?\n",
    "- Have you used other packages or tools that you've found helpful?\n",
    "\n",
    "For more, check out the [Facebook Prophet](https://github.com/facebookincubator/prophet) and [Pyflux](http://www.pyflux.com) projects.\n",
    "\n",
    "#### Connect with me on [LinkedIn](https://www.linkedin.com/in/jbalaban) and [Github](https://github.com/ultimatist)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": false,
   "nav_menu": {
    "height": "311px",
    "width": "412px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": "3",
   "toc_cell": false,
   "toc_position": {
    "height": "22px",
    "left": "1105px",
    "right": "20px",
    "top": "-1px",
    "width": "22px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
